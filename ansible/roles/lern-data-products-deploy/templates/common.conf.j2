application.env="{{ env }}"
telemetry.version="2.1"
default.parallelization="10"
spark_output_temp_dir="/mount/data/analytics/tmp/"
service.search.url="{{ service.search.url }}"
service.search.path="{{ service.search.path }}"
spark.cassandra.connection.host="{{groups['dp-cassandra'][0]}}"
cassandra.keyspace_prefix="{{ cassandra_keyspace_prefix }}"

storage.key.config="{{ dp_storage_key_config }}"
storage.secret.config="{{ dp_storage_secret_config }}"
reports.storage.key.config="{{ dp_reports_storage_key_config }}"
reports.storage.secret.config="{{ dp_reports_storage_secret_config }}"
cloud_storage_type="{{cloud_service_provider}}"

# cloud_storage_endpoint="{{ cloud_private_storage_endpoint | regex_replace('^[a-z]+://(.*)$', '\1') }}"
cloud_storage_endpoint="{{ cloud_private_storage_endpoint.split('/')[2]|lower }}"
cloud_storage_endpoint_with_protocol="{{ cloud_private_storage_endpoint }}"

# Joblog Kafka appender config for cluster execution
log.appender.kafka.enable="false"
log.appender.kafka.broker_host="{{groups['processing-cluster-kafka'][0]}}:9092"
log.appender.kafka.topic="{{ env }}.druid.events.log"

# Kafka connection configuration
kafka.consumer.brokerlist="{{groups['processing-cluster-kafka'][0]}}:9092"
kafka.consumer.topic="{{ env }}.analytics.job_queue"
no_of_jobs=42

# Spark Driver
spark.driver.memory=6g

spark.memory_fraction={{ spark.memory_fraction }}
spark.storage_fraction={{ spark.storage_fraction }}
spark.driver_memory="{{ spark.driver_memory }}"

#Monitor Jobs
monitor {
  notification {
    webhook_url = "{{ data_exhaust_webhook_url }}"
    channel = "{{ data_exhaust_Channel }}"
    token = "{{ data_exhaust_token }}"
    slack = true
    name = "{{ data_exhaust_name }}"
  }
}

#App ID & Channel ID
default.consumption.app.id="no_value"
default.channel.id="in.ekstep"
default.creation.app.id="no_value"

## Reports - Global config
cloud.container.reports="{{reports_container}}"

# course metrics container
course.metrics.cassandra.sunbirdKeyspace="sunbird"
course.metrics.cassandra.sunbirdCoursesKeyspace="sunbird_courses"
course.metrics.cloud.objectKey=""
course.metrics.cassandra.input.consistency="QUORUM"
es.host="http://{{groups['core-es'][0]}}"
es.port="9200"
es.composite.host="{{groups['composite-search-cluster'][0]}}"

# State admin user reports
admin.metrics.cloud.objectKey=""
admin.metrics.temp.dir="/mount/data/analytics/admin-user-reports"

#Assessment report config
es.scroll.size = 1000

#BestScore or Latst Updated Score
assessment.metrics.bestscore.report=true
assessment.metrics.supported.contenttype="SelfAssess"
assessment.metrics.supported.primaryCategories="{{ assessment_metric_primary_category }}"
spark.sql.caseSensitive=true

// Metric event config
metric.producer.id="pipeline.monitoring"
metric.producer.pid="dataproduct.metrics"
push.metrics.kafka=true
metric.kafka.broker="{{groups['processing-cluster-kafka']|join(':9092,')}}:9092"
metric.kafka.topic="{{ env }}.prom.monitoring.metrics"

//Postgres Config
postgres.db="{{postgres.db_name}}"
postgres.url="jdbc:postgresql://{{postgres.db_url}}:{{postgres.db_port}}/"
postgres.user="{{postgres.db_username}}"
postgres.pass="{{postgres.db_password}}"

sunbird_encryption_key="{{ core_vault_sunbird_encryption_key }}"

## Collection Exhaust Jobs Configuration -- Start ##
sunbird.user.keyspace="{{ user_table_keyspace }}"
sunbird.courses.keyspace="{{ course_keyspace }}"
sunbird.content.hierarchy.keyspace="{{ cassandra_hierarchy_store_keyspace }}"
sunbird.program.report.keyspace="{{ program_keyspace }}"
sunbird.user.cluster.host="{{ core_cassandra_host }}"
sunbird.program.report.host="{{ core_cassandra_host }}"
sunbird.courses.cluster.host="{{ core_cassandra_host }}"
sunbird.content.cluster.host="{{ core_cassandra_host }}"
sunbird.report.cluster.host="{{ report_cassandra_cluster_host }}"
sunbird.user.report.keyspace="{{ report_user_table_keyspace }}"
collection.exhaust.store.prefix=""
ml.exhaust.store.prefix="ml_reports"
postgres.table.job_request="{{ job_request_table }}"
postgres.table.dataset_metadata="{{ dataset_metadata_table }}"
## Collection Exhaust Jobs Configuration -- End ##

## Exhaust throttling variables
exhaust.batches.limit.per.channel={{ exhaust_batches_limit_per_channel }}
exhaust.file.size.limit.per.channel={{ exhaust_file_size_limit_bytes_per_channel }}

exhaust.parallel.batch.load.limit={{ exhaust_parallel_batch_load_limit }}
exhaust.user.parallelism={{ exhaust_user_parallelism }}

data_exhaust.batch.limit.per.request={{ data_exhaust_batch_limit_per_request }}

sunbird.course.optionalnodes="optionalnodes"
sunbird.course.redis.host={{ groups['redisall'][0] }}
sunbird.course.redis.port=6379
sunbird.course.redis.relationCache.id=5

org.search.private.api.url="{{ org_search_service_private_endpoint }}"
tenant.pref.read.private.api.url="{{ tenant_preferance_read_private_service_endpoint }}"

framework_read_api = "{{ framework_read_endpoint }}"
taxonomy.basePath = "{{ domain_url }}"
sunbird_instance_name="{{ sunbird_installation | default('Sunbird')}}"

redis.user.database.index="{{ redis.user.index }}"
redis.user.input.index="{{ redis.user.input_index }}"
redis.max.pipeline.size="{{ redis.max_pipeline_size }}"
redis.scan.count="{{ redis.scan_count }}"
redis.user.backup.dir="{{ redis.user.backup_dir }}"

cassandra.read.timeoutMS="{{ cassandra.read_timeout }}"
cassandra.query.retry.count="{{ cassandra.retry_count }}"
cassandra.input.consistency.level="{{ core_cassandra_read_consistency }}"